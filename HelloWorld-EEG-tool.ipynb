{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build version alpha 0.03\n",
    "# Author: Joseph O'Neill\n",
    "#\n",
    "# Tool usage:\n",
    "#   - To build a deep NN\n",
    "#   - To test the accuracy of the model in predicting timeseries multivariate classification\n",
    "# \n",
    "# Data:\n",
    "#   - EEG recordings from an EMOTIV EPOC+\n",
    "#   - EEG recording and file conversion from edf to csv with EMOTIV PRO software\n",
    "#   - EEG recordings in two sets of subvocalized words: hello, world\n",
    "#\n",
    "# Neural Network:\n",
    "#   - Conv. RNN based on the paper:\n",
    "#       Cascade and Parallel Conv. NN on EEG-based Intention Recogn for BCI\n",
    "#         by Lina Yao et al.\n",
    "#   - As of this build haven't decided on Cascade or Parallel\n",
    "#   - I am leaning towards trying the Cascade CRNN but it is still early\n",
    "#\n",
    "# Current usage abilities:\n",
    "#   - Loads in all the csv files with glob\n",
    "#   - ! EACH MAP IS MAPPED TO ITS CORRESPONDING ORIGINAL FILE NAME !\n",
    "#   - maps the files by word (hello vs world) into 2 dictionaries or file maps\n",
    "#       > (hello_file_map, world_file_map)\n",
    "#   - Converts the file maps from array into meshes and maps into mesh maps\n",
    "#       > (hello_mesh_map, world_mesh_map)\n",
    "#   - Takes the mesh mapping and uses the z-score standardization\n",
    "#      as instructed in the paper -> working towards Cascade CRNN\n",
    "#   - Saves Z standard meshes into a new Z_map\n",
    "#       > (hello_z_map, world_z_map)\n",
    "##########################\n",
    "# Added in Version a0.04 #\n",
    "##########################\n",
    "#   - Functions to simplify z_score_converion function\n",
    "#       > (mesh_mean(), mesh_sigma(), mesh_z())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to emotiv label meanings:\n",
    "# https://emotiv.gitbook.io/emotivpro/exported_data_files/edf_files\n",
    "\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob -- For Unix style reading patterns -- https://docs.python.org/3/library/glob.html\n",
    "# glob needed for *.csv\n",
    "hello_file_path = \"/home/joeyoneill/Desktop/cofc_research/HelloWorld-EEG/HelloWorld_Data/hello/*.csv\"\n",
    "world_file_path = \"/home/joeyoneill/Desktop/cofc_research/HelloWorld-EEG/HelloWorld_Data/world/*.csv\"\n",
    "\n",
    "\n",
    "helloFiles = glob.glob(hello_file_path)\n",
    "worldFiles = glob.glob(world_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads in all hello .csv files into file_map dictionary\n",
    "def read_map_emotiv_csv(df, filename, file_map):\n",
    "    \n",
    "    # delete EEG.Interpolated and EEG.Counter\n",
    "    # not needed and in the way of df slicing\n",
    "    del df['EEG.Interpolated']\n",
    "    del df['EEG.Counter']\n",
    "    del df['Timestamp']\n",
    "    \n",
    "    # saves needed columns into the df\n",
    "    # the 14 channel readings\n",
    "    # gets rid of excess\n",
    "    # tail gives us only the last 2000 ms (2 s)\n",
    "    # last 2000 ms needed due to procedure data was recorded\n",
    "    df = df[df.columns[0:14]].tail(255)\n",
    "           \n",
    "    # resets index making first index 0; needed for nomalized code\n",
    "    # delete 'index' needed because \n",
    "    # reset_index() causes 'index' column of orig indexes to be made\n",
    "    df = df.reset_index()\n",
    "    del df['index']\n",
    "    \n",
    "    # Transfers data from pd to a numpy array\n",
    "    # Saves numpy array in dictionary\n",
    "    # Array mapped to its filename\n",
    "    # Array Usage: df_as_arr[ts][iteration]\n",
    "    # such that ts is an integer timestep (0-255) not the actual Timestamp (Ts)\n",
    "    # iteration:\n",
    "    # 0 -> AF3, 1 -> F7, 2 -> F3, 3 -> FC5\n",
    "    # 4 -> T7, 5 -> P7, 6 -> O1, 7 -> O2, 8 -> P8\n",
    "    # 9 -> T8, 10 -> FC6, 11 -> F4, 12 -> F8, 13 -> AF4\n",
    "    file_map[filename[-7:]] = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads in all hello .csv files into hello_file_map dictionary\n",
    "hello_file_map = {}\n",
    "\n",
    "for filename in helloFiles:\n",
    "    # Read in the CSV File to the dataframe\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    # normalizes the df and maps values into hello_file_map\n",
    "    read_map_emotiv_csv(df, filename, hello_file_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads in all world .csv files into world_file_map dictionary\n",
    "world_file_map = {}\n",
    "\n",
    "for filename in worldFiles:\n",
    "    # Read in the CSV File to the dataframe\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    # normalizes the df and maps values into hello_file_map\n",
    "    read_map_emotiv_csv(df, filename, world_file_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the np.array version\n",
    "# of the data into mesh matrices as noted in\n",
    "# Cascade and Parallel Conv. NN on EEG-based Intention Recogn for BCI\n",
    "# by Lina Yao et al.\n",
    "'''\n",
    "Mesh matrix (such that each channel is their volatage at that timestep t):\n",
    "0   0   AF3 AF4 0   0\n",
    "F7  0   F3  F4  0   F8\n",
    "0   FC5 0   0   FC6 0\n",
    "T7  0   0   0   0   T8\n",
    "0   0   0   0   0   0 \n",
    "P7  0   0   0   0   P8\n",
    "0   O1  0   0   O2  0\n",
    "'''\n",
    "def convert_to_mesh_matrix(file_map, mesh_map):\n",
    "    for key in file_map.keys():\n",
    "        mesh_list = []\n",
    "        for i in range(len(file_map[key])):\n",
    "            # creates skeleton for the mesh matrix\n",
    "            # 6 x 7 2D matrix padded with zeros for spatial recognization\n",
    "            mesh = np.zeros((7, 6))\n",
    "            \n",
    "            # REMEMBER:\n",
    "            # 0 -> AF3, 1 -> F7, 2 -> F3, 3 -> FC5\n",
    "            # 4 -> T7, 5 -> P7, 6 -> O1, 7 -> O2, 8 -> P8\n",
    "            # 9 -> T8, 10 -> FC6, 11 -> F4, 12 -> F8, 13 -> AF4\n",
    "            \n",
    "            # AF3\n",
    "            mesh[0][2] = file_map[key][i][0]\n",
    "\n",
    "            # AF4\n",
    "            mesh[0][3] = file_map[key][i][13]\n",
    "\n",
    "            # F7\n",
    "            mesh[1][0] = file_map[key][i][1]\n",
    "\n",
    "            # F3\n",
    "            mesh[1][2] = file_map[key][i][2]\n",
    "\n",
    "            # F4\n",
    "            mesh[1][3] = file_map[key][i][11]\n",
    "\n",
    "            # F8\n",
    "            mesh[1][5] = file_map[key][i][12]\n",
    "\n",
    "            # FC5\n",
    "            mesh[2][1] = file_map[key][i][3]\n",
    "\n",
    "            # FC6\n",
    "            mesh[2][4] = file_map[key][i][10]\n",
    "\n",
    "            # T7\n",
    "            mesh[3][0] = file_map[key][i][4]\n",
    "\n",
    "            # T8\n",
    "            mesh[3][5] = file_map[key][i][9]\n",
    "\n",
    "            # P7\n",
    "            mesh[5][0] = file_map[key][i][5]\n",
    "\n",
    "            # P8\n",
    "            mesh[5][5] = file_map[key][i][8]\n",
    "\n",
    "            # O1\n",
    "            mesh[6][1] = file_map[key][i][6]\n",
    "\n",
    "            # O2\n",
    "            mesh[6][4] = file_map[key][i][7]\n",
    "\n",
    "            # adds newly created mesh matrix to the list\n",
    "            mesh_list.append(mesh)\n",
    "        \n",
    "        # maps the mesh list to its file name\n",
    "        mesh_map[key] = mesh_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of empty mesh mappings\n",
    "hello_mesh_map = {}\n",
    "world_mesh_map = {}\n",
    "\n",
    "# Converting rt -> mt and saving it to the mesh_maps\n",
    "convert_to_mesh_matrix(hello_file_map, hello_mesh_map)\n",
    "convert_to_mesh_matrix(world_file_map, world_mesh_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function returns the mean of the non-zero values of a mesh\n",
    "# Used to simplify z_score_conversion() function\n",
    "def mesh_mean(mesh, N_channels):\n",
    "    total = 0.0\n",
    "    # Getting the mean value of the mesh    \n",
    "    for i in range(len(mesh)):\n",
    "        for j in range(len(mesh[i])):\n",
    "            if mesh[i][j] != 0:\n",
    "                total = total + mesh[i][j]\n",
    "    return total / N_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function returns sigma value of the non-zero values of a mesh\n",
    "# Used to simplify z_score_conversion() function\n",
    "def mesh_sigma(mesh, mean, N_channels):\n",
    "    # Getting the sigma value of the mesh\n",
    "    total = 0.0\n",
    "    for i in range(len(mesh)):\n",
    "        for j in range(len(mesh[i])):\n",
    "            if mesh[i][j] != 0:\n",
    "                total = total + ((mesh[i][j] - mean)**2)\n",
    "    return math.sqrt(total / N_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function returns a z standardized mesh\n",
    "# Used to simplify z_score_conversion() function\n",
    "def mesh_z(mesh, mean, sigma):\n",
    "    # Z score normalization of mesh\n",
    "    z_mesh = np.zeros((7, 6))\n",
    "    for i in range(len(mesh)):\n",
    "        for j in range(len(mesh[i])):\n",
    "            if mesh[i][j] != 0:\n",
    "                z_val = (mesh[i][j] - mean) / sigma\n",
    "                z_mesh[i][j] = z_val\n",
    "    return z_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert from votage mesh mapping\n",
    "# to Z value mesh mapping\n",
    "#\n",
    "# Takes in mesh map, and empty Z map\n",
    "# returns a filled Z map of all converted file values\n",
    "def z_score_conversion(mesh_map, z_map, N_channels):\n",
    "    \n",
    "    # For each file\n",
    "    for key in mesh_map.keys():\n",
    "\n",
    "        z_mesh_list = []\n",
    "        \n",
    "        # for each mesh of the current file 0 - 254\n",
    "        for i in range(len(mesh_map[key])):\n",
    "            \n",
    "            # Getting the mean value of the mesh    \n",
    "            mean = mesh_mean(mesh_map[key][i], N_channels)\n",
    "            \n",
    "            # Getting the sigma value of the mesh\n",
    "            sigma = mesh_sigma(mesh_map[key][i], mean, N_channels)\n",
    "            \n",
    "            # Z score normalization of mesh\n",
    "            z_mesh = mesh_z(mesh_map[key][i], mean, sigma)\n",
    "            \n",
    "            # adds the mesh to its respective list to map to filename\n",
    "            z_mesh_list.append(z_mesh)\n",
    "        \n",
    "        # List mapped to filename\n",
    "        z_map[key] = z_mesh_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize empty Z mesh maps\n",
    "hello_z_map = {}\n",
    "world_z_map = {}\n",
    "\n",
    "# Number of EEG channels for mean purposes\n",
    "N_channels = 14\n",
    "\n",
    "# Converting voltage mesh -> z mesh\n",
    "z_score_conversion(hello_mesh_map, hello_z_map, N_channels)\n",
    "z_score_conversion(world_mesh_map, world_z_map, N_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello: 40\n",
      "world: 41\n"
     ]
    }
   ],
   "source": [
    "print(\"hello: \" + str(len(hello_z_map)) + \"\\nworld: \" + str(len(world_z_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
